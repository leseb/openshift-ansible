---
# input variables:
# - l_docker_upgrade
# - node_config_hook
# - openshift_pkg_version

# tasks file for openshift_node_upgrade

- name: stop services for upgrade
  import_tasks: upgrade/stop_services.yml

<<<<<<< HEAD
# Ensure actually install latest package.
- name: install docker upgrade rpm
  command: "{{ ansible_pkg_mgr }} install -y docker{{ '-' + docker_version }}"
  register: result
  until: result is succeeded
<<<<<<< HEAD
=======
- name: Stop node and openvswitch services
  service:
    name: "{{ item }}"
    state: stopped
  with_items:
  - "{{ openshift_service_type }}-node"
  - openvswitch
  failed_when: false

- name: Stop additional containerized services
  service:
    name: "{{ item }}"
    state: stopped
  with_items:
  - "{{ openshift_service_type }}-master-controllers"
  - "{{ openshift_service_type }}-master-api"
  - etcd_container
  failed_when: false
  when: openshift.common.is_containerized | bool

- name: Pre-pull node image
  command: >
    docker pull {{ openshift.node.node_image }}:{{ openshift_image_tag }}
  register: pull_result
  changed_when: "'Downloaded newer image' in pull_result.stdout"
  when: openshift.common.is_containerized | bool

- name: Pre-pull openvswitch image
  command: >
    docker pull {{ openshift.node.ovs_image }}:{{ openshift_image_tag }}
  register: pull_result
  changed_when: "'Downloaded newer image' in pull_result.stdout"
  when:
  - openshift.common.is_containerized | bool
  - openshift_use_openshift_sdn | bool

- include_tasks: docker/upgrade.yml
  vars:
    # We will restart Docker ourselves after everything is ready:
    skip_docker_restart: True
>>>>>>> Remove openshift.common.service_type
=======
>>>>>>> Deprecate using Ansible tests as filters
  when:
  - l_docker_upgrade is defined
  - l_docker_upgrade | bool

- name: Ensure cri-o is updated
  package:
    name: "{{ pkg_list | join (',') }}"
    state: latest
  when:
  - openshift_use_crio | bool
  register: crio_update
  until: crio_update is succeeded
  vars:
    pkg_list:
    - cri-o
    - cri-tools

- name: Remove CRI-O default configuration files
  file:
    path: "{{ item }}"
    state: absent
  with_items:
  - "/etc/cni/net.d/200-loopback.conf"
  - "/etc/cni/net.d/100-crio-bridge.conf"
  when: crio_update is changed

- name: Ensure crictl.yaml runtime-endpoint is updated
  yedit:
    src: /etc/crictl.yaml
    key: runtime-endpoint
    value: "{{ openshift_crio_var_sock }}"
  when:
  - openshift_use_crio | default(False) | bool

<<<<<<< HEAD
- name: install pre-pulled rpms.
  import_tasks: upgrade/rpm_upgrade_install.yml
=======
- name: Ensure containerized services stopped before Docker restart
  service:
    name: "{{ item }}"
    state: stopped
  with_items:
  - etcd_container
  - openvswitch
  - "{{ openshift_service_type }}-master-api"
  - "{{ openshift_service_type }}-master-controllers"
  - "{{ openshift_service_type }}-node"
  failed_when: false
  when: openshift.common.is_containerized | bool

- name: Stop rpm based services
  service:
    name: "{{ item }}"
    state: stopped
  with_items:
  - "{{ openshift_service_type }}-node"
  - openvswitch
  failed_when: false
  when: not openshift.common.is_containerized | bool
>>>>>>> Remove openshift.common.service_type

<<<<<<< HEAD
# TODO(michaelgugino): Remove in 3.12
- import_tasks: selinux_container_cgroup.yml

<<<<<<< HEAD
=======
>>>>>>> Upgrade to 3.10 with static pods
- include_tasks: "{{ node_config_hook }}"
  when: node_config_hook is defined
=======
- name: Upgrade openvswitch
  package:
    name: openvswitch
    state: latest
  when: not openshift.common.is_containerized | bool
  register: result
  until: result | success
>>>>>>> retry package operations

- import_tasks: upgrade/config_changes.yml

- import_tasks: dnsmasq_install.yml
- import_tasks: dnsmasq.yml

- name: ensure dnsmasq is always restarted
  debug:
    msg: "Restarting dnsmasq"
  # changed_when: True required for debug tasks to trigger handlers.
  changed_when: True
  notify:
  - reload systemd units
  - restart dnsmasq

<<<<<<< HEAD
# Need to flush handlers here so dnsmasq is restarted and daemon-reload
=======
- include_tasks: journald.yml

>>>>>>> Move journald setup to node tasks from master
- meta: flush_handlers

# Restart all services
- import_tasks: upgrade/restart.yml

- name: Approve node certificates when bootstrapping
<<<<<<< HEAD
  oc_csr_approve:
    oc_bin: "{{ hostvars[groups.oo_first_master.0]['first_master_client_binary'] }}"
    oc_conf: "{{ openshift.common.config_base }}/master/admin.kubeconfig"
    node_list:
    - "{{ l_kubelet_node_name | lower }}"
  delegate_to: "{{ groups.oo_first_master.0 }}"
  register: node_upgrade_oc_csr_approve
  retries: 30
  until: node_upgrade_oc_csr_approve is succeeded
=======
  oc_adm_csr:
    nodes: "{{ openshift.common.hostname | lower }}"
    timeout: 180
    fail_on_timeout: true
  delegate_to: "{{ groups.oo_first_master.0 }}"
  ignore_errors: true
  when: openshift_node_bootstrap | default(True) | bool

- name: Wait for node to be ready
  oc_obj:
    state: list
    kind: node
    name: "{{ openshift.common.hostname | lower }}"
  register: node_output
  delegate_to: "{{ groups.oo_first_master.0 }}"
  until: node_output.results.returncode == 0 and node_output.results.results[0].status.conditions | selectattr('type', 'match', '^Ready$') | map(attribute='status') | join | bool == True
  # Give the node three minutes to come back online.
  retries: 36
  delay: 5
>>>>>>> Upgrade to 3.10 with static pods

- import_tasks: journald.yml
